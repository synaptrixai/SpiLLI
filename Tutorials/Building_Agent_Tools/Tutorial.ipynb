{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda0f02b",
   "metadata": {},
   "source": [
    "# Building Tools for Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df074bfb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting using cus_id: cus_T42EpGqSccMdhc\n",
      "[Socket] Connected\n",
      "[Socket] Connected\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from SpinLLM import SpinChatModel\n",
    "\n",
    "# models to try: llama3.2:latest, gemma3:1b, llama3:instruct, llama3-groq-tool-use:8b, \n",
    "# different models can lead to different results in tool use\n",
    "# tool use requires careful finetuning of models and thus a lot of models fail to perform well for tool use\n",
    "# try different models to see how certain models can fail or hallucinate when using tools\n",
    "# the default model (llama3-groq-tool-use:8b) are fine tuned for tool use and thus provide a reasonable performance\n",
    "\n",
    "llm = SpinChatModel(\n",
    "    model_name= \"Gpt-Oss-20B\",#\"llama3-groq-tool-use:8b\",\n",
    "    encryption_path='/root/.spilli/SpiLLI.pem',\n",
    "    temperature=0.8,\n",
    "    max_tokens=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd7d0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "\n",
    "## 1.  What Kind of Tools Can You Build?\n",
    "\n",
    "| Tool Category | Typical Useâ€‘Case | Example Implementation |\n",
    "|---------------|------------------|------------------------|\n",
    "| **Web Search** | Fetch latest info from the internet | `SerpAPI` wrapper |\n",
    "| **Database Query** | Read/Write from SQL or NoSQL databases | `SQLDatabaseTool` |\n",
    "| **File I/O** | Read local files (CSV, TXT, JSON) | `FileReadTool` |\n",
    "| **API Calls** | Interact with external services (weather, finance) | `HTTPTool` |\n",
    "| **Mathematics** | Perform calculations or symbolic math | `CalculatorTool` |\n",
    "| **Data Processing** | Run Pandas transformations | `PandasTool` |\n",
    "| **Summarisation** | Summarise long documents | `LLMSummarizer` |\n",
    "| **Custom Business Logic** | Any domainâ€‘specific operation | `BaseTool` subclass |\n",
    "\n",
    "Below weâ€™ll implement a handful of these tools from scratch using SpiLLI and LangChain.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.  Building Custom Tools\n",
    "\n",
    "All tools in LangChain inherit from `BaseTool`.  \n",
    "The key components are:\n",
    "\n",
    "1. **`name`** â€“ short identifier used by the agent.\n",
    "2. **`description`** â€“ naturalâ€‘language explanation of what the tool does.\n",
    "3. **`_run`** â€“ the actual logic executed when the tool is called.\n",
    "\n",
    "### 2.1  A Simple Calculator Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29356ec0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "class CalculatorTool(BaseTool):\n",
    "    name:str = \"calculator\"\n",
    "    description:str = \"Use this tool to perform basic arithmetic or advanced math operations. Input should be a mathematical expression.\"\n",
    "\n",
    "    def _run(self, expression: str) -> str:\n",
    "        try:\n",
    "            # Warning: eval is dangerous; in production, use a math parser\n",
    "            result = eval(expression, {\"__builtins__\": {}})\n",
    "            return f\"The result is: {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "calculator_tool = CalculatorTool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24727763",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **Security note** â€“ Never expose `eval` to untrusted user input. In a real application, use a sandboxed math library (e.g., `sympy`, `mpmath`).\n",
    "\n",
    "### 4.2  A Fileâ€‘Reader Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72bc133",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "class FileReadTool(BaseTool):\n",
    "    name:str = \"file_reader\"\n",
    "    description:str = \"Read the contents of a file. Input should be a file path relative to the current working directory.\"\n",
    "\n",
    "    def _run(self, path: str) -> str:\n",
    "        try:\n",
    "            file_path = pathlib.Path(path).resolve()\n",
    "            if not file_path.exists():\n",
    "                return f\"File not found: {file_path}\"\n",
    "            content = file_path.read_text(encoding=\"utf-8\")\n",
    "            return f\"Contents of {file_path}: {content}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error reading file: {e}\"\n",
    "\n",
    "file_read_tool = FileReadTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51928f31-9833-4ece-8427-486bdf1085bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Contents of /app/Tutorials/Building_Agent_Tools/SpiLLI.txt: SpiLLI is used with LangChain to provide LLMs that can decide when and which tool to use and then generate a response using a chain-of-thought approach.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_read_tool.invoke('SpiLLI.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c14a2",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3  An External API Call Tool (e.g., Weather API)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09898959-c2f6-4cc5-990e-482a26392fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "class WeatherTool(BaseTool):\n",
    "    name:str = \"weather_api\"\n",
    "    description:str = (\n",
    "        \"Fetch current weather information for a city. Input should be the city name, e.g., 'Paris'. \"\n",
    "        \"You will need to register at https://openweathermap.org/api and set the environment variable \"\n",
    "        \"OPENWEATHERMAP_API_KEY.\"\n",
    "    )\n",
    "\n",
    "    def _run(self, city: str) -> str:\n",
    "        api_key = os.getenv(\"OPENWEATHERMAP_API_KEY\")\n",
    "        if not api_key:\n",
    "            return \"API key not configured. Set OPENWEATHERMAP_API_KEY environment variable.\"\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&units=metric&appid={api_key}\"\n",
    "        try:\n",
    "            resp = requests.get(url)\n",
    "            data = resp.json()\n",
    "            if resp.status_code != 200:\n",
    "                return f\"Error from API: {data.get('message', 'Unknown error')}\"\n",
    "            temp = data[\"main\"][\"temp\"]\n",
    "            desc = data[\"weather\"][0][\"description\"]\n",
    "            return f\"The current temperature in {city} is {temp}Â°C with {desc}.\"\n",
    "        except Exception as e:\n",
    "            return f\"Failed to fetch weather: {e}\"\n",
    "\n",
    "weather_tool = WeatherTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c975ffd7",
   "metadata": {},
   "source": [
    "\n",
    "> **Tip** â€“ Store your API keys securely (e.g., in a `.env` file or a secrets manager).\n",
    "\n",
    "\n",
    "\n",
    "## 3.  Putting Tools in an AI Agent\n",
    "\n",
    "Weâ€™ll now create an `AgentExecutor` that can choose among our tools based on a prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fcb74",
   "metadata": {},
   "source": [
    "\n",
    "Wrap tools into LangChain's Tool format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa05e89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain_community.tools import Tool\n",
    "from langchain_community.tools.file_management.read import ReadFileTool\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=calculator_tool._run,\n",
    "        name=calculator_tool.name,\n",
    "        description=calculator_tool.description\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=file_read_tool._run,\n",
    "        name=file_read_tool.name,\n",
    "        description=file_read_tool.description\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=weather_tool._run,\n",
    "        name=weather_tool.name,\n",
    "        description=weather_tool.description\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5386c",
   "metadata": {},
   "source": [
    "\n",
    "# Initialize an agent that can decide when to use a tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a3ef5b-29a4-4f63-8f2d-0bc09b079066",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd876623-6976-453c-bbe0-521129f7854b",
   "metadata": {},
   "source": [
    "> **Tip** â€“  see what the internals look like for the agent.\n",
    ">  you can change the agent type to different pre-built types, changing how the agents are prompted, which leads to different performance in terms of tool use success rate and halucination problems.\n",
    " You can try a few to get a sense of this vulnerability (see avilable pre-made agents at: https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent_types.AgentType.html). \n",
    "\n",
    "> then in the exercises you will write custom agent types to see how you can optimize your prompts to get the best results for a given llm or fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c05d17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4.  Running the Agent\n",
    "\n",
    "Below are a few example queries to see the agent in action.\n",
    "\n",
    "### 4.1  Simple Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeeb88b-c1e8-48bb-bfa4-37a4ac7747cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "run1 =await agent.ainvoke({'messages':HumanMessage(\"What is 23 + 42?\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e11d0e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is 23 + 42?', additional_kwargs={}, response_metadata={}, id='68500b82-a318-42bf-a538-80f59fabb79d'), AIMessage(content='<|channel|>analysis<|message|>We need to compute 23+42=65. Use calculator tool.<|end|><|start|>assistant<|channel|>final<|message|>Action: calculator\\nAction Input: \"23 + 42\"[EOG]', additional_kwargs={}, response_metadata={}, id='lc_run--019b4dcb-f3d8-7d11-99a0-467766fdcde8-0')]}\n"
     ]
    }
   ],
   "source": [
    "print(run1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12361e33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "*Expected output (something like):*  \n",
    "```\n",
    "Thinking...\n",
    "Tool: calculator | Input: 23 + 42\n",
    "Result: The result is: 65\n",
    "...\n",
    "Answer: The result is: 65.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae26f9e",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2  Read a File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd5179f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Please read the file ./SpiLLI.txt. and summarize its contents', additional_kwargs={}, response_metadata={}, id='6ecb9419-015d-442f-958f-3f3b6a4f3b2c'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}, id='lc_run--019b4dd1-9d14-7350-9c4b-9b1b95efbd83-0', tool_calls=[{'name': 'file_reader', 'args': {'path': './SpiLLI.txt'}, 'id': 'call_file_reader_1065', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Contents of /app/Tutorials/Building_Agent_Tools/SpiLLI.txt: SpiLLI is used with LangChain to provide LLMs that can decide when and which tool to use and then generate a response using a chain-of-thought approach.', name='file_reader', id='dadb9215-a071-41a0-8a2a-0f7b509b9b2f', tool_call_id='call_file_reader_1065'),\n",
       "  AIMessage(content='<|channel|>analysis<|message|>We need to summarize the file contents. The file content: \"SpiLLI is used with LangChain to provide LLMs that can decide when and which tool to use and then generate a response using a chain-of-thought approach.\"\\n\\nWe need to produce a summary. The user asked: \"Please read the file ./SpiLLI.txt. and summarize its contents\". So we should respond with a summary. The content is short. Summarize: \"SpiLLI is a tool integrated with LangChain that enables large language models to autonomously decide which tools to use and generate responses via chain-of-thought reasoning.\" That is the answer.<|end|><|start|>assistant<|channel|>final<|message|>SpiLLI is a LangChainâ€‘based tool that lets large language models autonomously decide which external tools to invoke and then generate responses using a chainâ€‘ofâ€‘thought reasoning process.[EOG]', additional_kwargs={}, response_metadata={}, id='lc_run--019b4dd1-a0e6-7171-ac3b-2ba175e9aefb-0')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.ainvoke({\"messages\":HumanMessage(\"Please read the file ./SpiLLI.txt. and summarize its contents\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e449c",
   "metadata": {},
   "source": [
    "> **Observation:** You can note how the LLM generated the tool call to read the file and then summarizes the content it in the final answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1dd3a",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3  Weather Query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "556f1e6a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"What's the current weather in New York?\", additional_kwargs={}, response_metadata={}, id='b97e225e-ccec-4785-84c5-4bb88a532b42'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}, id='lc_run--88e1f0c4-fbfd-42f9-be58-20f6951b81aa-0', tool_calls=[{'name': 'weather_api', 'args': {'city': 'New York'}, 'id': 'call_weather_api_2789', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='API key not configured. Set OPENWEATHERMAP_API_KEY environment variable.', name='weather_api', id='ab95d1d1-cde6-4adc-8382-6345e0422a06', tool_call_id='call_weather_api_2789'),\n",
       "  AIMessage(content=\"I'm sorry, but I can't fetch the current weather information for New York without the API key. Please set the OPENWEATHERMAP_API_KEY environment variable to proceed.\", additional_kwargs={}, response_metadata={}, id='lc_run--a68fa486-4aa7-4df8-82da-6697f7c94ab6-0')]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.invoke({\"messages\":HumanMessage(\"What's the current weather in New York?\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c76b980",
   "metadata": {},
   "source": [
    "\n",
    "*Expected output:*  \n",
    "```\n",
    "{'messages': [HumanMessage(content=\"What's the current weather in New York?\", additional_kwargs={}, response_metadata={}, id='b97e225e-ccec-4785-84c5-4bb88a532b42'),\n",
    "  AIMessage(content='', additional_kwargs={}, response_metadata={}, id='lc_run--88e1f0c4-fbfd-42f9-be58-20f6951b81aa-0', tool_calls=[{'name': 'weather_api', 'args': {'city': 'New York'}, 'id': 'call_weather_api_2789', 'type': 'tool_call'}]),\n",
    "  ToolMessage(content='API key not configured. Set OPENWEATHERMAP_API_KEY environment variable.', name='weather_api', id='ab95d1d1-cde6-4adc-8382-6345e0422a06', tool_call_id='call_weather_api_2789'),\n",
    "  AIMessage(content=\"I'm sorry, but I can't fetch the current weather information for New York without the API key. Please set the OPENWEATHERMAP_API_KEY environment variable to proceed.\", additional_kwargs={}, response_metadata={}, id='lc_run--a68fa486-4aa7-4df8-82da-6697f7c94ab6-0')]}\n",
    "```\n",
    "\n",
    "*Warning:* Watch for hullucinations in the generated response steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567a17d4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 5.  Extending the Toolkit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639675a",
   "metadata": {},
   "source": [
    "\n",
    "You can now create as many tools as you need. Some ideas:\n",
    "\n",
    "| Domain | Possible Tool |\n",
    "|--------|---------------|\n",
    "| **Finance** | Stock price fetcher (Yahoo Finance, Alpha Vantage) |\n",
    "| **NLP** | Text sentiment analyzer, entity extractor |\n",
    "| **Knowledge Base** | Query a local knowledge graph or a vector store |\n",
    "| **Automation** | Send emails, schedule calendar events |\n",
    "| **Data Science** | Run a Pandas pipeline, train a lightweight model |\n",
    "\n",
    "Just subclass `BaseTool`, implement `_run`, and add it to the `tools` list.\n",
    "\n",
    "---\n",
    "\n",
    "## 6.  Recap\n",
    "\n",
    "1. **Install** LangChain and dependencies.  \n",
    "2. **Set up** an LLM using SpiLLI.  \n",
    "3. **Implement** tools by inheriting `BaseTool`.  \n",
    "4. **Wrap** each tool in LangChainâ€™s `Tool` object.  \n",
    "5. **Create** an `Agent` that can reason and choose tools.  \n",
    "6. **Run** the agent with naturalâ€‘language prompts.\n",
    "\n",
    "Happy hacking! ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff52a91b-3938-4ba2-8f17-1706ff573803",
   "metadata": {},
   "source": [
    "## 7. Further Study: Writing a Custom Agent Executor\n",
    "\n",
    "### Exercise: Look at how custom agent graphs can be written using LangGraph and use your custom agent flow instead of the above default agent if you are feeling ambitious. You'll learn a lot beyond just using the above default agent framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6192e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpiLLI",
   "language": "python",
   "name": "spilli"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
